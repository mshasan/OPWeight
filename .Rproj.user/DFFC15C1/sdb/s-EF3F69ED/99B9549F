{
    "collab_server" : "",
    "contents" : "#' @title Perform Optimal Pvalue Weighting\n#'\n#' @description A function to perform weighted pvalue multiple hypothesis test.\n#' This function compute the probabilities of the tests' ranks, and consequently\n#' the weights, then provides the number of rejected null hypothesis and the list of\n#' the rejected pvalues as well as the corresponing filter statistics.\n#'\n#' @param  pvalue vector of pvalues of the test statistics\n#' @param filter vector of filter statistics\n#' @param test vector of test statistics\n#' @param prob_givenEffect the probabilities of the filters or filters' ranks given\n#' the mean of the filter effects\n#' @param ranks determine what type of probabilities \\code{prob_givenEffect} is used\n#' @param mean_filterEffect mean filter effect of the true alternatives\n#' @param mean_testEffect mean test effect of the true alterantives\n#' @param effectType type of effect sizes; c(\"continuous\", \"binary\")\n#' @param alpha significance level of the hypothesis test\n#' @param nrep number of replications for importance sampling, default value is 10,000,\n#' can be increased to obtain smoother probability curves\n#' @param tail right-tailed or two-tailed hypothesis test. default is right-tailed test.\n#' For the two-tailed test, either \\code{test} or \\code{prob_givenEffect}\n#' or \\code{mean_testEffect} must needs to be provided\n#' @param delInterval interval between the \\code{delta} values of a sequence. Note that,\n#' \\code{delta} is a LaGrange multiplier, necessary to normalize the weight\n#' @param method type of methods is used to obtain the results; c(\"BH\", \"BON\"),\n#' Benjemini-Hochberg or Bonferroni\n#' @param ... Arguments passed to internal functions\n#'\n#' @details If one wants to test \\deqn{H_0: epsilon_i = 0 vs. H_a: epsilon_i > 0,}\n#' then the \\code{mean_testEffect}  and \\code{mean_filterEffect} should be mean of the test\n#' and filter effect sizes, respectively. This is called hypothesis testing for\n#' the continuous effect sizes.\\cr\n#'\n#' If one wants to test \\deqn{H_0: epsilon_i = 0 vs. H_a: epsilon_i = epsilon,}\n#' then \\code{mean_testEffect} and \\code{mean_filterEffect} should be median or\n#' any discrete value of the test and filter effect sizes. This is called hypothesis\n#' testing for the Binary effect sizes, where \\code{epsilon} refers to a fixed value.\\cr\n#'\n#' Internally, \\code{opw} function compute the \\code{prob_givenEffect} and consequently\n#' the weights, then uses the pvalues to make conclusions about hypotheses.\n#' Therefore, if \\code{prob_givenEffect} is given then \\code{mean_filterEffect}\n#' and are redundant, and should not be provided to the funciton.\n#' Although \\code{prob_givenEffect} is not required to the function,\n#' One can compute \\code{prob_givenEffect} by using either the function\n#' \\code{\\link{prob_rank_givenEffect}} if \\code{ranks == TRUE} or\n#' \\code{\\link{dnorm}} if \\code{ranks == FALSE}.\\cr\n#'\n#' The function internally compute \\code{mean_filterEffect} and \\code{mean_testEffect}\n#' from a simple linear regression with box-cox transformation between the test\n#' and filter statistics, where the filters are regressed on the test statistics.\n#' Then the estimated \\code{mean_filterEffect} and\n#' \\code{mean_testEffect} are used to obtian the \\code{prob_givenEffect} and the weights.\n#' Thus, in order to apply the function properly, it is crucial to understand the\n#' uses of the parameters \\code{test}, \\code{mean_filterEffect} and \\code{mean_testEffect}.\n#' If the test statistics are provided, and \\code{mean_filterEffect} and\n#' \\code{mean_testEffect} are not provided then the supplied test statistics will\n#' be used to compute the relationship between the filter statistics and the\n#' test statistics. If none of them are given then the \\code{pvalue} will be used to\n#' compute the test statistics, and therefore these test statistics will be considered\n#' as the right-tailed test statistics.\\cr\n#'\n#' If \\code{mean_filterEffect} and \\code{mean_testEffect} are provided then the\n#' test statistics are not necessary at all. However, if one of the mean effects\n#' are not given, then the missing mean effect will be computed internally.\n#' In addition, for the the two-tailed test, one must need to provide either\n#' \\code{test} or \\code{prob_givenEffect} or \\code{mean_testEffect}.\n#'\n#' @author Mohamad S. Hasan and Paul Schliekelman\n#'\n#' @export\n#'\n#' @import OPWeight prob_rank_givenEffect\n#' @import OPWeight weight_binary\n#' @import OPWeight weight_continuous\n#' @import qvalue qvalue\n#'\n#' @seealso \\code{\\link{prob_rank_givenEffect}} \\code{\\link{weight_binary}}\n#' \\code{\\link{weight_continuous}} \\code{\\link{qvalue}} \\code{\\link{dnorm}}\n#'\n#'\n#' @return \\code{totalTests} total number of hypothesis tests evaluated\n#' @return \\code{propNulls} estimated propotion of the true null hypothesis\n#' @return \\code{probGivenEffect} probability of the ranks given the mean filter effect,\n#' p(rank | ey = mean_filterEffect)\n#' @return \\code{weight} normalized weight\n#' @return \\code{rejections} total number of rejections\n#' @return \\code{rejections_list} list of rejected pvalues and the corresponding\n#' filter statistics\n#'\n#'\n#' @examples\n#' m = 1000\n#' set.seed(3)\n#' filters = runif(m, min = 0, max = 2.5)          # filter statistics\n#' H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false\n#' tests = rnorm(m, mean = H * filters)            # Z-score\n#' pvals = 1 - pnorm(tests)                        # pvalue\n#'\n#' results <- opw(pvalue = pvals, filter = filters, ranks = FALSE,\n#'                      effectType = \"continuous\", method = \"BH\")\n#' results2 <- opw(pvalue = pvals, filter = filters, test = tests, ranks = TRUE,\n#'                effectType = \"continuous\", tail = 2, method = \"BH\")\n#'\n#' mod <- lm(log(filters) ~ tests)\n#' et = mean(tests)\n#' ey = mod$coef[[1]] + mod$coef[[2]]*et\n#' results3 <- opw(pvalue = pvals, filter = filters, ranks = FALSE,\n#'                mean_filterEffect = ey, mean_testEffect = et, tail = 2,\n#'                effectType = \"continuous\", method = \"BH\")\n#'\n#' # compute the probabilities of rank for 1 to 100 tests\n#' library(qvalue)\n#' ranks <- 1:m\n#' null = qvalue(p = pvals, pi0.method = \"bootstrap\")$pi0\n#' m0 = ceiling(null*m)\n#' m1 = m - m0\n#' probs <- sapply(ranks, prob_rank_givenEffect, et = ey, ey = ey,\n#'                                         nrep = 10000, m0 = m0, m1 = m1)\n#' results4 <- opw(pvalue = pvals, filter = filters, prob_givenEffect = probs,\n#'                      effectType = \"continuous\", tail = 2, method = \"BH\")\n#'\n#' probs2 <- dnorm(filters, mean = mean(filters), sd = 1)\n#' results5 <- opw(pvalue = pvals, filter = filters, prob_givenEffect = probs2,\n#'                      effectType = \"continuous\", tail = 2, method = \"BH\")\n#'\n#============================================================================\n# function to apply opw methods on data\n#---------------------------------------------------\n# Input:\n#----------------------------\n# pvalue = vector of pvalues\n# filter = vector of filter statistics\n# prob_givenEffect = the probabilities of the filters or filters' ranks given\n# the mean of the filter effects\n# ranks = determine what type of probabilities \\code{prob_givenEffect} is used\n# mean_filterEffect = filter effect size\n# mean_testEffect = test effect size\n# effectType = type of effect size c(\"binary\",\"continuous\")\n# alpha = significance level of the hypotheis test\n# nrep = number of replications for importance sampling\n# tail = right-tailed or two-tailed hypothesis test. default is two-tailed test\n# delInterval = interval between the delta values of a sequence\n# method = Benjamini_HOchberg (BH) or Bonferroni (BON)\n\n# internal parameters:-----\n# m = number of hypothesis test\n# null = proportion of true null hypothesis\n# m0 =  number of the true null tests\n# m1 = number of the true alternative tests\n# test =  compute test statistics from the pvalues if not given\n# test_effect_vec = estiamted number of the true alternaitve test statistics\n# mean_testEffect = mean test effect sizes of the true alternaive hypotheis\n# mean_filterEffect = mean filter effect sizes of the true alternaive hypotheis\n# prob = probailities of the ranks given the mean effect size\n# wgt = weights\n# Data = create a data set\n# OD = odered by covariate\n# odered.pvalues = odered pvalues for all tests\n# padj = adjusted pvalues for FDR uses\n\n# Output:\n#-------------------------\n# totalTests = total number of hypothesis tests\n# propNulls = estimated propotion of the true null hypothesis\n# probGivenEffect = probability of the ranks given the mean filter effect,\n#                                           p(rank | ey = mean_filterEffet)\n# weight = normalized weight\n# rejections = total number of rejections\n# rejections_list = list of rejected pvalues and corresponding filter statistics\n#-------------------------------------------------------------------------------\n\nopw <- function(pvalue, filter, test = NULL, prob_givenEffect = NULL, ranks = FALSE,\n                mean_filterEffect = NULL, mean_testEffect = NULL,\n                effectType = c(\"continuous\", \"binary\"), alpha = .05, nrep = 10000,\n                tail = 1L, delInterval = .0001, method = c(\"BH\", \"BON\"), ... )\n    {\n        # compute number of tests------------\n        m = length(pvalue)\n        null = qvalue(p = pvalue, pi0.method = \"bootstrap\")$pi0\n        m0 = ceiling(null*m)\n        m1 = m - m0\n\n        # determine the side of the tests-------------\n        if(is.null(mean_testEffect) & is.null(test) & is.null(prob_givenEffect))\n            {message(\"using right-tailed test since test needs to be computed from the pvalue\")\n        }\n\n        # compute test statistics from the pvalues---------\n        if(is.null(test)) {\n            test <- qnorm(pvalue, lower.tail = FALSE)\n        } else {\n            test <- test\n        }\n\n        test[which(!is.finite(test))] <- NA\n\n        # estimae the true alterantive test effect sizes----------------\n        if(m1 == 0){test_effect_vec <- 0\n        } else {\n            if(tail == 1){test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]\n            } else {test_effect_vec <-  sort(abs(test), decreasing = TRUE)[1:m1]\n                message(\"for two-tailed test, eihter test or prob_givenEffect or\n                        mean_testEffect must needs to be provided\")\n            }\n        }\n\n        # estiamte the mean test effect size-------------\n        if(!is.null(mean_testEffect)){mean_testEffect <- mean_testEffect\n        } else {\n            if(effectType == \"continuous\"){\n                mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)\n            } else {\n                mean_testEffect <- median(test_effect_vec, na.rm = TRUE)\n            }\n        }\n\n        # estiamte lambda from box-cox transformation----------------\n        bc <- boxcox(filter ~ test)\n        lambda <- bc$x[which.max(bc$y)]\n\n        # estimate the mean filter effect size------------------\n        if(!is.null(mean_filterEffect)){mean_filterEffect <- mean_filterEffect\n        } else {\n            if(lambda == 0){model <- lm(log(filter + .0001) ~ test)\n            } else {\n                model <- lm(filter^lambda ~ test)\n            }\n            mean_filterEffect <- model$coef[[1]] + model$coef[[2]]*mean_testEffect\n        }\n\n        # compute the probability of the filter given the mean filter effect\n        if(!is.null(prob_givenEffect)){prob <- prob_givenEffect\n        } else {\n            if(ranks == FALSE){\n                if(lambda == 0){\n                    prob <- dnorm(log(filter + .0001), mean = mean_filterEffect, sd = 1)\n                } else {\n                    prob <- dnorm(filter^lambda, mean = mean_filterEffect, sd = 1)\n                }\n            } else {\n                prob <- sapply(1:m, prob_rank_givenEffect, et = mean_filterEffect,\n                               ey = mean_filterEffect, nrep = nrep, m0 = m0, m1 = m1)\n            }\n        }\n\n        # compute the weights------------\n        if(effectType == \"continuous\"){\n            wgt = weight_continuous(alpha = alpha, et = mean_testEffect, m = m,\n                                    tail = tail, delInterval = delInterval, prob = prob)\n        } else {\n            wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = m, m1 = m1,\n                                tail = tail, delInterval = delInterval, prob = prob)\n        }\n\n        # formulate a data set-------------\n        Data = tibble(pvalue, filter)\n        OD <- Data[order(Data$filter, decreasing=T), ]\n        Ordered.pvalue <- OD$pvalue\n\n        if(method == \"BH\"){\n            padj <- p.adjust(Ordered.pvalue/wgt, method = \"BH\")\n            rejections_list = OD[which((padj <= alpha) == TRUE), ]\n        } else {\n            rejections_list = OD[which((Ordered.pvalue <= alpha*wgt/m) == TRUE), ]\n        }\n\n        # outputs--------------\n        n_rejections = dim(rejections_list)[1]\n\n        return(list(totalTests = m, propNulls = null,\n                    probGivenEffect = prob, weight = wgt,\n                    rejections = n_rejections, rejections_list = rejections_list))\n    }\n\n\n\n\n\n",
    "created" : 1494685605681.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "763315616",
    "id" : "99B9549F",
    "lastKnownWriteTime" : 1494708705,
    "last_content_update" : 1494708705179,
    "path" : "C:/Users/Apu-Jerrica/Google Drive/My R Packages/OPWeight/R/opw.R",
    "project_path" : "R/opw.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}