{
    "collab_server" : "",
    "contents" : "#' @title Perform Optimal Pvalue Weighting\n#'\n#' @description A function to perform weighted pvalue multiple hypothesis test.\n#' This function compute the probabilities of the ranks of the filter statistics\n#' given the effect sizes, and consequently the weights if neighter the weights\n#' nor the probabilities are given. Then provides the number of rejected null\n#' hypothesis and the list of the rejected pvalues as well as the corresponing\n#' filter statistics.\n#'\n#' @param pvalue a vector of pvalues of the test statistics\n#' @param filter a vector of filter statistics\n#' @param weight optional weight vector not required\n#' @param ranksProb probabilities of the ranks of the filters given the mean effect\n#' @param mean_filterEffect mean filter effect of the true alternatives\n#' @param mean_testEffect mean test effect of the true alterantives\n#' @param effectType type of effect sizes; c(\"continuous\", \"binary\")\n#' @param alpha significance level of the hypothesis test\n#' @param nrep number of replications for importance sampling, default value is 10,000,\n#' can be increased to obtain smoother probability curves\n#' @param tail right-tailed or two-tailed hypothesis test. default is right-tailed test.\n#' @param delInterval interval between the \\code{delta} values of a sequence. Note that,\n#' \\code{delta} is a LaGrange multiplier, necessary to normalize the weight\n#' @param method type of methods is used to obtain the results; c(\"BH\", \"BON\"),\n#' Benjemini-Hochberg or Bonferroni\n#' @param ... Arguments passed to internal functions\n#'\n#' @details If one wants to test \\deqn{H_0: epsilon_i = 0 vs. H_a: epsilon_i > 0,}\n#' then the \\code{mean_testEffect}  and \\code{mean_filterEffect} should be mean of the test\n#' and filter effect sizes, respectively. This is called hypothesis testing for\n#' the continuous effect sizes.\\cr\n#'\n#' If one wants to test \\deqn{H_0: epsilon_i = 0 vs. H_a: epsilon_i = epsilon,}\n#' then \\code{mean_testEffect} and \\code{mean_filterEffect} should be median or\n#' any discrete value of the test and filter effect sizes. This is called hypothesis\n#' testing for the Binary effect sizes, where \\code{epsilon} refers to a fixed value.\\cr\n#'\n#' The main goal of the function is to compute the probabilities of the ranks from\n#' the pvalues and the filter statistics, consequently the weights. Although \\code{weights}\n#' \\code{ranksProb} are optional, \\code{opw} has the options so that one can compute\n#' the probabilities and the weights externally if necessary (see examples).\\cr\n#'\n#' Internally, \\code{opw} function compute the \\code{ranksProb} and consequently\n#' the weights, then uses the pvalues to make conclusions about hypotheses.\n#' Therefore, if \\code{ranksProb} is given then \\code{mean_filterEffect}\n#' and are redundant, and should not be provided to the funciton.\n#' Although \\code{ranksProb} is not required to the function,\n#' One can compute \\code{ranksProb} by using the function\n#' \\code{\\link{prob_rank_givenEffect}}.\\cr\n#'\n#' The function internally compute \\code{mean_filterEffect} and \\code{mean_testEffect}\n#' from a simple linear regression with box-cox transformation between the test\n#' and filter statistics, where the filters are regressed on the test statistics.\n#' Thus, filters need to be positive to apply \\code{boxcox} from the \\code{R}\n#' library \\code{MASS}. Then the estimated \\code{mean_filterEffect} and\n#' \\code{mean_testEffect} are used to obtian the \\code{ranksProb} and the weights.\n#' Thus, in order to apply the function properly, it is crucial to understand the\n#' uses \\code{mean_filterEffect} and \\code{mean_testEffect}. If \\code{mean_filterEffect} and\n#' \\code{mean_testEffect} are not provided then the test statistics computed from\n#' the pvalues will be used to compute the relationship between the filter\n#' statistics and the test statistics.\\cr\n#'\n#' If one of the mean effects \\code{mean_filterEffect} and \\code{mean_testEffect}\n#' are not provided then the missing mean effect will be computed internally.\n#'\n#'\n#' @author Mohamad S. Hasan and Paul Schliekelman\n#'\n#' @export\n#'\n#' @import qvalue qvalue\n#' @import tibble tibble\n#' @import MASS boxcox\n#'\n#' @seealso \\code{\\link{prob_rank_givenEffect}} \\code{\\link{weight_binary}}\n#' \\code{\\link{weight_continuous}} \\code{\\link{qvalue}} \\code{\\link{dnorm}}\n#'\n#'\n#' @return \\code{totalTests} total number of hypothesis tests evaluated\n#' @return \\code{nullProp} estimated propotion of the true null hypothesis\n#' @return \\code{ranksProb} probability of the ranks given the mean filter effect,\n#' p(rank | ey = mean_filterEffect)\n#' @return \\code{weight} normalized weight\n#' @return \\code{rejections} total number of rejections\n#' @return \\code{rejections_list} list of rejected pvalues and the corresponding\n#' filter statistics\n#'\n#'\n#' @examples\n#' # generate pvalues and filter statistics\n#' m = 1000\n#' set.seed(3)\n#' filters = runif(m, min = 0, max = 2.5)          # filter statistics\n#' H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false\n#' tests = rnorm(m, mean = H * filters)            # Z-score\n#' pvals = 1 - pnorm(tests)                        # pvalue\n#'\n#' # general use\n#' results <- opw(pvalue = pvals, filter = filters, effectType = \"continuous\",\n#'                                               method = \"BH\")\n#'\n#' # supply the mean effects for both the filters and the tests externally\n#' mod <- lm(log(filters) ~ tests)\n#' et = mean(tests)\n#' ey = mod$coef[[1]] + mod$coef[[2]]*et\n#' results2 <- opw(pvalue = pvals, filter = filters,\n#'                mean_filterEffect = ey, mean_testEffect = et, tail = 2,\n#'                effectType = \"continuous\", method = \"BH\")\n#'\n#' # supply the rank probabilities externally\n#' library(qvalue)\n#' ranks <- 1:m\n#' nullProp = qvalue(p = pvals, pi0.method = \"bootstrap\")$pi0\n#' m0 = ceiling(nullProp*m)\n#' m1 = m - m0\n#' probs <- sapply(ranks, prob_rank_givenEffect, et = ey, ey = ey,\n#'                                         nrep = 10000, m0 = m0, m1 = m1)\n#' results3 <- opw(pvalue = pvals, filter = filters, ranksProb = probs,\n#'                  ranks = FALSE, effectType = \"continuous\", tail = 2, method = \"BH\")\n#'\n#' # supply weight externally\n#' wgt <- weight_continuous(alpha = .05, et = et, m = m, ranksProb = probs)\n#' results4 <- opw(pvalue = pvals, filter = filters, weight = wgt,\n#'                         effectType = \"continuous\", alpha = .05, method = \"BH\")\n#'\n#===============================================================================\n# function to apply opw methods on data\n#---------------------------------------------------\n# Input:\n#----------------------------\n# pvalue = vector of pvalues\n# filter = vector of filter statistics\n# ranksProb = the probabilities of the filters or filters' ranks given\n# the mean of the filter effects\n# mean_filterEffect = filter effect size\n# mean_testEffect = test effect size\n# effectType = type of effect size c(\"binary\",\"continuous\")\n# alpha = significance level of the hypotheis test\n# nrep = number of replications for importance sampling\n# tail = right-tailed or two-tailed hypothesis test. default is two-tailed test\n# delInterval = interval between the delta values of a sequence\n# method = Benjamini_HOchberg (BH) or Bonferroni (BON)\n\n# internal parameters:-----\n# m = number of hypothesis test\n# nullProp = proportion of true null hypothesis\n# m0 =  number of the true null tests\n# m1 = number of the true alternative tests\n# test =  compute test statistics from the pvalues if not given\n# test_effect_vec = estiamted number of the true alternaitve test statistics\n# mean_testEffect = mean test effect sizes of the true alternaive hypotheis\n# mean_filterEffect = mean filter effect sizes of the true alternaive hypotheis\n# ranksProb = probailities of the ranks given the mean effect size\n# wgt = weights\n# Data = create a data set\n# OD = odered by covariate\n# odered.pvalues = odered pvalues for all tests\n# padj = adjusted pvalues for FDR uses\n\n# Output:\n#-------------------------\n# totalTests = total number of hypothesis tests\n# nullProp = estimated propotion of the true null hypothesis\n# ranksProb = probability of the ranks given the mean filter effect,\n#                                           p(rank | ey = mean_filterEffet)\n# weight = normalized weight\n# rejections = total number of rejections\n# rejections_list = list of rejected pvalues and corresponding filter statistics\n#-------------------------------------------------------------------------------\n\nopw <- function(pvalue, filter, weight = NULL, ranksProb = NULL, mean_filterEffect = NULL,\n                mean_testEffect = NULL, effectType = c(\"continuous\", \"binary\"),\n                alpha = .05, nrep = 10000, tail = 1L, delInterval = .0001,\n                method = c(\"BH\", \"BON\"), ... )\n    {\n        # compute the number of tests------------\n        m = length(pvalue)\n        nullProp = qvalue(p = pvalue, pi0.method = \"bootstrap\")$pi0\n        m0 = ceiling(nullProp*m)\n        m1 = m - m0\n\n\n        # formulate a data set-------------\n        Data = tibble(pvalue, filter)\n        OD <- Data[order(Data$filter, decreasing=T), ]\n        Ordered.pvalue <- OD$pvalue\n\n\n        #check whether weight is provided------------\n        if(!is.null(weight)){\n            wgt <- weight\n        } else {\n\n            # compute test statistics from the pvalues---------\n            test <- qnorm(pvalue/tail, lower.tail = FALSE)\n            test[which(!is.finite(test))] <- NA\n\n            # estimate the true alterantive test effect sizes----------------\n            if(m1 == 0){\n                test_effect_vec <- 0\n            } else {\n                test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]\n            }\n\n            # estimate the mean test effect size-------------\n            if(!is.null(mean_testEffect)){\n                mean_testEffect <- mean_testEffect\n            } else {\n                if(effectType == \"continuous\"){\n                    mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)\n                } else {\n                    mean_testEffect <- median(test_effect_vec, na.rm = TRUE)\n                }\n            }\n\n\n            #check whether filter ranks probability is provided------------\n            if(!is.null(ranksProb)){\n                ranksProb <- ranksProb\n            } else {\n                # estimate the mean filter effect size------------------\n                if(!is.null(mean_filterEffect)){\n                    mean_filterEffect <- mean_filterEffect\n                } else {\n                    # check whether the filters are positive for the box-cox--------\n                    if(any(filter <= 0)){\n                        stop(\"filter statistics need to be positive\")\n                    }\n\n                    bc <- boxcox(filter ~ test)\n                    lambda <- bc$x[which.max(bc$y)]\n\n                    if(lambda == 0){\n                        model <- lm(log(filter + .0001) ~ test)\n                    } else {\n                        model <- lm(filter**lambda ~ test)\n                    }\n                    mean_filterEffect <- model$coef[[1]] + model$coef[[2]]*mean_testEffect\n                }\n\n                message(\"computing rank probabilities\")\n                # compute the probability of the rank of the filter given the mean effect\n                ranksProb <- sapply(1:m, prob_rank_givenEffect, et = mean_filterEffect,\n                               ey = mean_filterEffect, nrep = nrep, m0 = m0, m1 = m1)\n\n                message(\"finished computing the rank probabilities\")\n            }\n\n            # compute the weights (always right-tailed)------------\n            message(\"computing weights\")\n            if(effectType == \"continuous\"){\n                wgt = weight_continuous(alpha = alpha, et = mean_testEffect, m = m,\n                                        tail = 1, delInterval = delInterval, ranksProb = ranksProb)\n            } else {\n                wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = m, m1 = m1,\n                                    tail = 1, delInterval = delInterval, ranksProb = ranksProb)\n            }\n            message(\"finished computing the weights\")\n        }\n\n        message(\"comparing pvalues with thresholds\")\n        if(method == \"BH\"){\n            padj <- p.adjust(Ordered.pvalue/wgt, method = \"BH\")\n            rejections_list = OD[which((padj <= alpha) == TRUE), ]\n        } else {\n            rejections_list = OD[which((Ordered.pvalue <= alpha*wgt/m) == TRUE), ]\n        }\n\n\n        # outputs--------------\n        n_rejections = dim(rejections_list)[1]\n\n        return(list(totalTests = m, nullProp = nullProp,\n                    ranksProb = ranksProb, weight = wgt,\n                    rejections = n_rejections, rejections_list = rejections_list))\n    }\n\n\n\n\n\n",
    "created" : 1495554804609.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "3202922567",
    "id" : "5DBD62D1",
    "lastKnownWriteTime" : 1495653264,
    "last_content_update" : 1495653264265,
    "path" : "C:/Users/mshasan/Google Drive/My R Packages/OPWeight/R/opw.R",
    "project_path" : "R/opw.R",
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}