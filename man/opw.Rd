% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/opw.R
\name{opw}
\alias{opw}
\title{Perform Optimal pvalue Weighting}
\usage{
opw(pvalue, filter, test = NULL, ranksProb = NULL,
  mean_filterEffect = NULL, mean_testEffect = NULL,
  effectType = c("continuous", "binary"), alpha = 0.05, nrep = 10000,
  tail = 1L, delInterval = 1e-04, method = c("BH", "BON"), ...)
}
\arguments{
\item{pvalue}{vector of pvalues of the test statistics}

\item{filter}{vector of filter statistics}

\item{test}{vector of test statistics}

\item{ranksProb}{the probabilities of the ranks given the mean filter effect}

\item{mean_filterEffect}{mean filter effect of the true alternatives}

\item{mean_testEffect}{mean test effect of the true alterantives}

\item{effectType}{type of effect sizes; c("continuous", "binary")}

\item{alpha}{significance level of the hypotheis test}

\item{nrep}{number of replications for importance sampling, default value is 10,000,
can be increased to obtain smoother probability curves}

\item{tail}{right-tailed or two-tailed hypothesis test. default is right-tailed test.
For the two-tailed test, either \code{mean_testEffect} or \code{test} statistics
must need to be provided}

\item{delInterval}{interval between the \code{delta} values of a sequence. Note that,
\code{delta} is a lagrange multiplier, necessary to normalize the weight}

\item{method}{type of methods is used to obtain the results; c("BH", "BON"),
Benjemini-Hochburg or Bonferroni}

\item{...}{Arguments passed to internal functions}
}
\value{
\code{totalTests} total number of hypothesis tests evaluated

\code{propNulls} estimated propotion of the true null hypothesis

\code{ranksProb} probability of the ranks given the mean filter effect,
p(rank | ey = mean_filterEffect)

\code{weight} normalized weight

\code{rejections} total number of rejections

\code{rejections_list} list of rejected pvalues and the corresponding
filter statistics
}
\description{
A function to perform the weighted pvalue multiple hypothesis test.
This function compute the probabilities of the tests' ranks, and consequently
the weights, then provides the number of rejected nyll hypothesis and the list of
the rejected pvlaues as well as the corresponing filter statistics.
}
\details{
If one wants to test \deqn{H_0: epsilon_i = 0 vs. H_a: epsilon_i > 0,}
then the \code{mean_testEffect}  and \code{mean_filterEffect} should be mean of the test
and filter effect sizes, respectively. This is called hypothesis testing for
the continuous effect sizes.\cr

If one wants to test \deqn{H_0: epsilon_i = 0 vs. H_a: epsilon_i = epsilon,}
then \code{mean_testEffect} and \code{mean_filterEffect} should be median or
any discrete value of the test and filter effect sizes. This is called hypothesis
testing for the Binary effect sizes, where \code{epsilon} refers to a fixed value.\cr

Internally, the function comute the \code{rankProb} and consequently the weights,
then uses the pvalues to make conclusion about hypotheses. Therefore, if
\code{ranksProb} is given then \code{test}, \code{mean_filterEffect}
and \code{mean_testEffect} are redundant, should not be provided to the funciton.
Although \code{ranksProb} is not required to the function, One can compute
\code{ranksProb} by using the function \code{\link{prob_rank_givenEffect}}.\cr

The function internally compute \code{mean_filterEffect} and \code{mean_testEffect}
from a simple linear regression with box-cox transformation between the test
and filter statistics, where filter is regress on the test statistics.
Then the estimated \code{mean_filterEffect} and
\code{mean_testEffect} are used to obtian the \code{ranksProb} and the weights.
Thus, in order to apply the function properly, it is crucial to understand the
uses of the parameters \code{test}, \code{mean_filterEffect} and \code{mean_testEffect}.
If the test statistics are provided, and \code{mean_filterEffect} and
\code{mean_testEffect} are not provided then the supplied test statistics will
be used to compute the relationship between the filter statistics and the
test statistics. If none of them are given then the \code{pvalue} will be used to
compute the test statistics, and therefore these test statistics will be considered
as the right-tailed test statistics.\cr

If \code{mean_filterEffect} and \code{mean_testEffect} are provided then the
test statistics are not necessary at all. However, if one of the mean effects
are not given, then the missing mean effect will be computed internally.
In addition, for the the two-tailed test, one must need to provide either \code{test}
or \code{mean_filterEffect}.
}
\examples{
m = 1000
set.seed(3)
filters = runif(m, min = 0, max = 2.5)          # filter statistics
H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false
tests = rnorm(m, mean = H * filters)            # Z-score
pvals = 1 - pnorm(tests)                        # pvalue

results <- opw(pvalue = pvals, filter = filters, effectType = "continuous",
                        method = "BH")
results2 <- opw(pvalue = pvals, filter = filters, test = tests,
               effectType = "continuous", tail = 2, method = "BH")

mod <- lm(log(filters) ~ tests)
et = mean(tests)
ey = mod$coef[[1]] + mod$coef[[2]]*et
results3 <- opw(pvalue = pvals, filter = filters, mean_filterEffect = ey,
               mean_testEffect = et, tail = 2, effectType = "continuous", method = "BH")

# compute the probabilities of rank for 1 to 100 tests
library(qvalue)
ranks <- 1:m
null = qvalue(p = pvals, pi0.method = "bootstrap")$pi0
m0 = ceiling(null*m)
m1 = m - m0
probs <- sapply(ranks, prob_rank_givenEffect, et = ey, ey = ey,
                                        nrep = 10000, m0 = m0, m1 = m1)
results4 <- opw(pvalue = pvals, filter = filters, ranksProb = probs,
                     effectType = "continuous", tail = 2, method = "BH")

}
\seealso{
\code{\link{prob_rank_givenEffect}} \code{\link{weight_binary}}
\code{\link{weight_binary}} \code{\link{qvalue}}
}
\author{
Mohamad S. Hasan, mshasan@uga.edu
}
