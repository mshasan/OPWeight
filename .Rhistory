p_ecdf <- ggplot(Data, aes(x = pval)) +
stat_ecdf(geom = "step")+
labs(x = "pvalues", title="empirical cumulative distribution")+
theme(plot.title = element_text(size = rel(.7)))
grid.arrange(hist_pval, hist_filter, pval_filter, p_ecdf,
ncol = 2, heights = c(7, 7), top = "Airway: data summary")
library(OPWeight)
knitr::opts_chunk$set(tidy = FALSE, cache = TRUE, autodep = TRUE)
Data <- tibble(test=de_res_air$stat, pval=de_res_air$pvalue, filter=de_res_air$baseMean)
barlines <- "#1F3552"
hist_pval <- ggplot(Data, aes(x = Data$pval)) +
geom_histogram(colour = barlines, fill = "#4281AE")+
labs(x = "pvalues")
hist_filter <- ggplot(Data, aes(x = Data$filter)) +
geom_histogram( colour = barlines, fill = "#4274AE") +
labs(x = "filter statistics")
#scale_x_continuous(limits = c(0, 100000), breaks=seq(0, 100000, 50000))
pval_filter <- ggplot(Data, aes(x = rank(-Data$filter), y = -log10(pval))) +
geom_point()+
labs(x = "ranks of filters", y = "-log(pvalue)")
#scale_x_continuous(limits = c(0, 100000), breaks=seq(0, 100000, 50000))
p_ecdf <- ggplot(Data, aes(x = pval)) +
stat_ecdf(geom = "step")+
labs(x = "pvalues", title="empirical cumulative distribution")+
theme(plot.title = element_text(size = rel(.7)))
grid.arrange(hist_pval, hist_filter, pval_filter, p_ecdf,
ncol = 2, heights = c(7, 7), top = "Airway: data summary")
library(OPWeight)
library(devtools)
build()
library(OPWeight)
library(OPWeight)
library(devtools)
?check
R CMD Rd2pdf OPWeight
getwd()
check(cleanup = FALSE, manual = TRUE, path = getwd())
check(cleanup = FALSE,manual = TRUE,path = getwd())
Sys.which(Sys.getenv("R_QPDF", "qpdf"))
Sys.getenv("PATH"
)
pandoc-citeproc
browseVignettes(package = "OPWeight")
system.file(package = "OPWeight")
browseVignettes(package = "BiocStyle")
install.packages("XML")
library(OPWeight)
library(OPWeight)
knitr::opts_chunk$set(tidy = FALSE, cache = TRUE, autodep = TRUE)
library("ggplot2")
library("airway")
library("DESeq2")
library(gridExtra)
library(cowplot)
library(tibble)
library(qvalue)
library(MASS)
data("airway", package = "airway")
dds <- DESeqDataSet(se = airway, design = ~ cell + dex)
dds <- DESeq(dds)
de_res_air <- as.data.frame(results(dds))
colnames(de_res_air)
dim(de_res_air)
library("OPWeight")
opw_results <- opw(pvalue = de_res_air$pvalue, filter = de_res_air $baseMean,
test = de_res_air$stat, alpha = .05, tail = 2,
effectType = "continuous", method = "BH")
names(opw_results)
opw_results$propNulls
opw_results$rejections
m = opw_results$totalTests
ranks = 1:m
probs = opw_results$probGivenEffect
weights = opw_results$weight
dat = data.frame(ranks, probs, weights)
p_prob = ggplot(dat, aes(x = ranks, y = probs)) + geom_point(size = .5, col="firebrick4") +
labs(y = "p(rank | effect)")
p_weight = ggplot(dat, aes(x = ranks, y = weights)) + geom_point(size = .5, col="firebrick4")
grid.arrange(p_prob, p_weight, ncol = 2)
Data <- tibble(test=de_res_air$stat, pval=de_res_air$pvalue, filter=de_res_air$baseMean)
barlines <- "#1F3552"
hist_pval <- ggplot(Data, aes(x = Data$pval)) +
geom_histogram(colour = barlines, fill = "#4281AE")+
labs(x = "pvalues")
hist_filter <- ggplot(Data, aes(x = Data$filter)) +
geom_histogram( colour = barlines, fill = "#4274AE") +
labs(x = "filter statistics")
pval_filter <- ggplot(Data, aes(x = rank(-Data$filter), y = -log10(pval))) +
geom_point()+
labs(x = "ranks of filters", y = "-log(pvalue)")
p_ecdf <- ggplot(Data, aes(x = pval)) +
stat_ecdf(geom = "step")+
labs(x = "pvalues", title="empirical cumulative distribution")+
theme(plot.title = element_text(size = rel(.7)))
grid.arrange(hist_pval, hist_filter, pval_filter, p_ecdf,
ncol = 2, heights = c(7, 7), top = "Airway: data summary")
# estimate the true null and alternative test sizes------
m = length(Data$pval); m
null = qvalue(Data$pval, pi0.method="bootstrap")$pi0; null
m0 = ceiling(null*m); m0
m1 = m - m0; m1
# fit box-cox regression
#--------------------------------
bc <- boxcox(Data$filter ~ Data$test, plotit = FALSE)
lambda <- bc$x[which.max(bc$y)]; lambda
model <- lm(Data$filter^lambda ~ Data$test)
# lambda = 0. Therefore, we use log-transformation
model <- lm(log(Data$filter) ~ Data$test)
# etimated test efects of the true altrnatives------------
test_effect = if(m1 == 0) {0
} else {sort(abs(Data$test), decreasing = T)[1:m1]}		# two-tailed test
# for the continuous effects etimated mean effects
mean_testEffect = mean(test_effect, na.rm = T)
mean_testEffect
mean_filterEffect = model$coef[[1]] + model$coef[[2]]*mean_testEffect
mean_filterEffect
# for the binary effects estiamted median effects
mean_testEffect = median(test_effect, na.rm = T)
mean_testEffect
mean_filterEffect = model$coef[[1]] + model$coef[[2]]*mean_testEffect
mean_filterEffect
names(opw_results)
opw_results$rejections
library(OPWeight)
library(OPWeight)
library(OPWeight)
library(OPWeight)
2^4
2**4
3^3
3**3
3**4
library(OPWeight)
library(OPWeight)
build()
library(devtools)
build()
prob_rank_givenEffect <- function(k, et, ey, nrep = 10000, m0, m1)
{
m = m0 + m1
t <- rnorm(nrep, et, 1)
p0 <- pnorm(-t)
p1 <- pnorm(ey - t)
mean0 <- (m0 - 1)*p0 + m1*p1 + 1
mean1 <- m0*p0 + (m1 - 1)*p1 + 1
var0 <- (m0 - 1)*p0*(1 - p0) + m1*p1*(1 - p1)
var1 <- m0*p0*(1 - p0) + (m1 - 1)*p1*(1 - p1)
prob <- ifelse(et == 0, mean(dnorm(k, mean0, sqrt(var0))),
mean(dnorm(k, mean1, sqrt(var1))))
pb <- tkProgressBar(title = "progress bar", min = 0,
max = m, width = 300)
setTkProgressBar(pb, k, label=paste( round(k/m*100, 0),
"% done"))
close(pb)
return(prob)
}
ranks <- 1:1000
prob <- sapply(ranks, prob_rank_givenEffect, et = 2, ey = 1, nrep = 10000,
m0 = 500, m1 = 500)
library(tcltk)
ranks <- 1:1000
prob <- sapply(ranks, prob_rank_givenEffect, et = 2, ey = 1, nrep = 10000,
m0 = 500, m1 = 500)
prob_rank_givenEffect <- function(k, et, ey, nrep = 10000, m0, m1)
{
m = m0 + m1
t <- rnorm(nrep, et, 1)
p0 <- pnorm(-t)
p1 <- pnorm(ey - t)
mean0 <- (m0 - 1)*p0 + m1*p1 + 1
mean1 <- m0*p0 + (m1 - 1)*p1 + 1
var0 <- (m0 - 1)*p0*(1 - p0) + m1*p1*(1 - p1)
var1 <- m0*p0*(1 - p0) + (m1 - 1)*p1*(1 - p1)
prob <- ifelse(et == 0, mean(dnorm(k, mean0, sqrt(var0))),
mean(dnorm(k, mean1, sqrt(var1))))
pb <- winProgressBar(title = "progress bar", min = 0,
max = m, width = 300)
setWinProgressBar(pb, k, title=paste( round(k/m*100, 0),
"% done"))
close(pb)
return(prob)
}
prob <- sapply(ranks, prob_rank_givenEffect, et = 2, ey = 1, nrep = 10000,
m0 = 500, m1 = 500)
prob_rank_givenEffect <- function(k, et, ey, nrep = 10000, m0, m1)
{
m = m0 + m1
t <- rnorm(nrep, et, 1)
p0 <- pnorm(-t)
p1 <- pnorm(ey - t)
mean0 <- (m0 - 1)*p0 + m1*p1 + 1
mean1 <- m0*p0 + (m1 - 1)*p1 + 1
var0 <- (m0 - 1)*p0*(1 - p0) + m1*p1*(1 - p1)
var1 <- m0*p0*(1 - p0) + (m1 - 1)*p1*(1 - p1)
prob <- ifelse(et == 0, mean(dnorm(k, mean0, sqrt(var0))),
mean(dnorm(k, mean1, sqrt(var1))))
pb <- winProgressBar(title = "progress bar", min = 0, max = m, width = 300)
setWinProgressBar(pb, k, title = paste(round(k/m*100), "% done"))
close(pb)
return(prob)
}
ranks <- 1:1000
prob <- sapply(ranks, prob_rank_givenEffect, et = 2, ey = 1, nrep = 10000,
m0 = 500, m1 = 500)
prob_rank_givenEffect <- function(k, et, ey, nrep = 10000, m0, m1, monitor = FALSE)
{
m = m0 + m1
t <- rnorm(nrep, et, 1)
p0 <- pnorm(-t)
p1 <- pnorm(ey - t)
mean0 <- (m0 - 1)*p0 + m1*p1 + 1
mean1 <- m0*p0 + (m1 - 1)*p1 + 1
var0 <- (m0 - 1)*p0*(1 - p0) + m1*p1*(1 - p1)
var1 <- m0*p0*(1 - p0) + (m1 - 1)*p1*(1 - p1)
prob <- ifelse(et == 0, mean(dnorm(k, mean0, sqrt(var0))),
mean(dnorm(k, mean1, sqrt(var1))))
pb <- winProgressBar(title = "progress bar", min = 0, max = m, width = 300)
setWinProgressBar(pb, k, title = paste(round(k/m*100), "% done"))
close(pb)
return(prob)
}
prob_rank_givenEffect <- function(k, et, ey, nrep = 10000, m0, m1, monitor = FALSE)
{
m = m0 + m1
t <- rnorm(nrep, et, 1)
p0 <- pnorm(-t)
p1 <- pnorm(ey - t)
mean0 <- (m0 - 1)*p0 + m1*p1 + 1
mean1 <- m0*p0 + (m1 - 1)*p1 + 1
var0 <- (m0 - 1)*p0*(1 - p0) + m1*p1*(1 - p1)
var1 <- m0*p0*(1 - p0) + (m1 - 1)*p1*(1 - p1)
prob <- ifelse(et == 0, mean(dnorm(k, mean0, sqrt(var0))),
mean(dnorm(k, mean1, sqrt(var1))))
if(monitor != FALSE){
pb <- winProgressBar(title = "progress bar", min = 0, max = m, width = 300)
setWinProgressBar(pb, k, title = paste(round(k/m*100), "% done"))
close(pb)
}
return(prob)
}
prob <- sapply(ranks, prob_rank_givenEffect, et = 2, ey = 1, nrep = 10000,
m0 = 500, m1 = 500, monitor = FALSE)
plot(ranks,prob)
prob <- sapply(ranks, prob_rank_givenEffect, et = 2, ey = 1, nrep = 10000,
m0 = 500, m1 = 500, monitor = TRUE)
opw <- function(pvalue, filter, prob_givenEffect = NULL, ranks = FALSE,
mean_filterEffect = NULL, mean_testEffect = NULL,
effectType = c("continuous", "binary"), alpha = .05, nrep = 10000,
tail = 1L, delInterval = .0001, method = c("BH", "BON"), ... )
{
# compute the number of tests------------
m = length(pvalue)
nullProp = qvalue(p = pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
# determine the side of the tests-------------
if(any(filter <= 0)){
stop("filter statistics need to be positive")
}
# compute test statistics from the pvalues---------
if(tail == 1){
test <- qnorm(pvalue, lower.tail = FALSE)
} else {
test <- qnorm(pvalue/2, lower.tail = FALSE)
}
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# estimate lambda from the box-cox transformation----------------
bc <- boxcox(filter ~ test)
lambda <- bc$x[which.max(bc$y)]
# estimate the mean filter effect size------------------
if(!is.null(mean_filterEffect)){
mean_filterEffect <- mean_filterEffect
} else {
if(lambda == 0){
model <- lm(log(filter + .0001) ~ test)
} else {
model <- lm(filter**lambda ~ test)
}
mean_filterEffect <- model$coef[[1]] + model$coef[[2]]*mean_testEffect
}
# compute the probability of the filter given the mean filter effect
message("computing probabilities")
if(!is.null(prob_givenEffect)){
prob <- prob_givenEffect
} else {
if(ranks == FALSE){
if(lambda == 0){
prob <- dnorm(log(filter + .0001), mean = 0, sd = 1)
} else {
prob <- dnorm(filter**lambda, mean = 0, sd = 1)
}
} else {
prob <- sapply(1:m, prob_rank_givenEffect, et = mean_filterEffect,
ey = mean_filterEffect, nrep = nrep, m0 = m0, m1 = m1)
}
}
message("finished computing the probabilities")
# compute the weights (always right-tailed)------------
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect, m = m,
tail = 1, delInterval = delInterval, prob = prob)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = m, m1 = m1,
tail = 1, delInterval = delInterval, prob = prob)
}
message("finished computing the weights")
# formulate a data set-------------
Data = tibble(pvalue, filter)
OD <- Data[order(Data$filter, decreasing=T), ]
Ordered.pvalue <- OD$pvalue
if(method == "BH"){
padj <- p.adjust(Ordered.pvalue/wgt, method = "BH")
rejections_list = OD[which((padj <= alpha) == TRUE), ]
} else {
rejections_list = OD[which((Ordered.pvalue <= alpha*wgt/m) == TRUE), ]
}
# outputs--------------
n_rejections = dim(rejections_list)[1]
return(list(totalTests = m, propNulls = nullProp,
probGivenEffect = prob, weight = wgt,
rejections = n_rejections, rejections_list = rejections_list))
}
results2 <- opw(pvalue = pvals, filter = filters, ranks = TRUE,
effectType = "continuous", tail = 2, method = "BH")
# generate pvalues and filter statistics
m = 1000
set.seed(3)
filters = runif(m, min = 0, max = 2.5)          # filter statistics
H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false
tests = rnorm(m, mean = H * filters)            # Z-score
pvals = 1 - pnorm(tests)                        # pvalue
# ranks = FLASE to use probability from the normal density
results <- opw(pvalue = pvals, filter = filters, ranks = FALSE,
effectType = "continuous", method = "BH")
# ranks = TRUE to use ranks probability
results2 <- opw(pvalue = pvals, filter = filters, ranks = TRUE,
effectType = "continuous", tail = 2, method = "BH")
library(qvalue)
library(MASS)
library(tibble)
# generate pvalues and filter statistics
m = 1000
set.seed(3)
filters = runif(m, min = 0, max = 2.5)          # filter statistics
H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false
tests = rnorm(m, mean = H * filters)            # Z-score
pvals = 1 - pnorm(tests)                        # pvalue
# ranks = FLASE to use probability from the normal density
results <- opw(pvalue = pvals, filter = filters, ranks = FALSE,
effectType = "continuous", method = "BH")
# ranks = TRUE to use ranks probability
results2 <- opw(pvalue = pvals, filter = filters, ranks = TRUE,
effectType = "continuous", tail = 2, method = "BH")
weight_binary <- function(alpha, et, m, m1, tail = 1L, delInterval = .0001, prob)
{
prob <- prob/sum(prob, na.rm = T)
delta <- seq(0, 1, delInterval)
findDelta <- function(delta)
{
weight <- tail*(m/alpha)*pnorm(et/2 + 1/et*log(delta*m/(alpha*m1*prob)),
lower.tail = FALSE)
return(sum(weight, na.rm = TRUE))
}
weightSumVec <- vapply(delta, findDelta, 1)
deltaOut <- delta[min(abs(weightSumVec - m)) == abs(weightSumVec - m)]
deltaOut <- ifelse(length(deltaOut) > 1, .0001, deltaOut)
weight.out <- tail*(m/alpha)*pnorm(et/2 + 1/et*log(deltaOut*m/(alpha*m1*prob)),
lower.tail = FALSE)
sumWeight <- sum(weight.out, na.rm = TRUE)
normWeight <- if(sumWeight == 0) {rep(1, m)} else {weight.out/sumWeight*m}
return(normWeight)
}
weight_continuous <- function(alpha, et, m, tail = 1L, delInterval = .0001, prob)
{
prob <- prob/sum(prob, na.rm = T)
delta <- seq(0, 1, delInterval)
findDelta <- function(delta)
{
weight <- tail*(m/alpha)*pnorm(et/2 + 1/et*log(delta/(alpha*prob)),
lower.tail=FALSE)
return(sum(weight, na.rm = TRUE))
}
weightSumVec <- vapply(delta, findDelta, 1)
deltaOut <- delta[min(abs(weightSumVec - m)) == abs(weightSumVec - m)]
deltaOut <- ifelse(length(deltaOut) > 1, .0001, deltaOut)
weight.out <- tail*(m/alpha)*pnorm(et/2 + 1/et*log(deltaOut/(alpha*prob)),
lower.tail=FALSE)
sumWeight <- sum(weight.out, na.rm = TRUE)
normWeight <- if(sumWeight == 0) {rep(1, m)} else {weight.out/sumWeight*m}
return(normWeight)
}
results2 <- opw(pvalue = pvals, filter = filters, ranks = TRUE,
effectType = "continuous", tail = 2, method = "BH")
opw <- function(pvalue, filter, prob_givenEffect = NULL, ranks = FALSE,
mean_filterEffect = NULL, mean_testEffect = NULL,
effectType = c("continuous", "binary"), alpha = .05, nrep = 10000,
tail = 1L, delInterval = .0001, method = c("BH", "BON"), monitor = FALSE, ... )
{
# compute the number of tests------------
m = length(pvalue)
nullProp = qvalue(p = pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
# determine the side of the tests-------------
if(any(filter <= 0)){
stop("filter statistics need to be positive")
}
# compute test statistics from the pvalues---------
if(tail == 1){
test <- qnorm(pvalue, lower.tail = FALSE)
} else {
test <- qnorm(pvalue/2, lower.tail = FALSE)
}
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# estimate lambda from the box-cox transformation----------------
bc <- boxcox(filter ~ test)
lambda <- bc$x[which.max(bc$y)]
# estimate the mean filter effect size------------------
if(!is.null(mean_filterEffect)){
mean_filterEffect <- mean_filterEffect
} else {
if(lambda == 0){
model <- lm(log(filter + .0001) ~ test)
} else {
model <- lm(filter**lambda ~ test)
}
mean_filterEffect <- model$coef[[1]] + model$coef[[2]]*mean_testEffect
}
# compute the probability of the filter given the mean filter effect
message("computing probabilities")
if(!is.null(prob_givenEffect)){
prob <- prob_givenEffect
} else {
if(ranks == FALSE){
if(lambda == 0){
prob <- dnorm(log(filter + .0001), mean = 0, sd = 1)
} else {
prob <- dnorm(filter**lambda, mean = 0, sd = 1)
}
} else {
prob <- sapply(1:m, prob_rank_givenEffect, et = mean_filterEffect,
ey = mean_filterEffect, nrep = nrep, m0 = m0, m1 = m1,
monitor = monitor)
}
}
message("finished computing the probabilities")
# compute the weights (always right-tailed)------------
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect, m = m,
tail = 1, delInterval = delInterval, prob = prob)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = m, m1 = m1,
tail = 1, delInterval = delInterval, prob = prob)
}
message("finished computing the weights")
# formulate a data set-------------
Data = tibble(pvalue, filter)
OD <- Data[order(Data$filter, decreasing=T), ]
Ordered.pvalue <- OD$pvalue
if(method == "BH"){
padj <- p.adjust(Ordered.pvalue/wgt, method = "BH")
rejections_list = OD[which((padj <= alpha) == TRUE), ]
} else {
rejections_list = OD[which((Ordered.pvalue <= alpha*wgt/m) == TRUE), ]
}
# outputs--------------
n_rejections = dim(rejections_list)[1]
return(list(totalTests = m, propNulls = nullProp,
probGivenEffect = prob, weight = wgt,
rejections = n_rejections, rejections_list = rejections_list))
}
results2 <- opw(pvalue = pvals, filter = filters, ranks = TRUE,
effectType = "continuous", tail = 2, method = "BH", monitor = FALSE)
results2 <- opw(pvalue = pvals, filter = filters, ranks = TRUE,
effectType = "continuous", tail = 2, method = "BH", monitor = TRUE)
library(OPWeight)
install.packages("Rcpp")
library(OPWeight)
